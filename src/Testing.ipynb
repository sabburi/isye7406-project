{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BWH', 'BWD', 'BWA', 'GBH', 'GBD', 'GBA', 'IWH', 'IWD', 'IWA', 'LBH', 'LBD', 'LBA', 'SBH', 'SBD', 'SBA', 'WHH', 'WHD', 'WHA', 'SJH', 'SJD', 'SJA', 'VCH', 'VCD', 'VCA', 'BSH', 'BSD', 'BSA', 'Bb1X2', 'BbMxH', 'BbAvH', 'BbMxD', 'BbAvD', 'BbMxA', 'BbAvA', 'BbOU', 'BbMx>2.5', 'BbAv>2.5', 'BbMx<2.5', 'BbAv<2.5', 'BbAH', 'BbAHh', 'BbMxAHH', 'BbAvAHH', 'BbMxAHA', 'BbAvAHA', 'PSH', 'PSD', 'PSA', 'PSCH', 'PSCD', 'PSCA']\n",
      "    Div       Date     HomeTeam    AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
      "418  E0 2010-08-14  Aston Villa    West Ham   3.0   0.0   H   2.0   0.0   H   \n",
      "419  E0 2010-08-14    Blackburn     Everton   1.0   0.0   H   1.0   0.0   H   \n",
      "420  E0 2010-08-14       Bolton      Fulham   0.0   0.0   D   0.0   0.0   D   \n",
      "421  E0 2010-08-14       Bolton      Fulham   0.0   0.0   D   0.0   0.0   D   \n",
      "422  E0 2010-08-14      Chelsea   West Brom   6.0   0.0   H   2.0   0.0   H   \n",
      "423  E0 2010-08-14   Sunderland  Birmingham   2.0   2.0   D   1.0   0.0   H   \n",
      "424  E0 2010-08-14    Tottenham    Man City   0.0   0.0   D   0.0   0.0   D   \n",
      "425  E0 2010-08-14        Wigan   Blackpool   0.0   4.0   A   0.0   3.0   A   \n",
      "426  E0 2010-08-14       Wolves       Stoke   2.0   1.0   H   2.0   0.0   H   \n",
      "427  E0 2010-08-15    Liverpool     Arsenal   1.0   1.0   D   0.0   0.0   D   \n",
      "\n",
      "     ... Squad_Home  Age_Home  Foreigners_Home  Total Market Value_Home  \\\n",
      "418  ...         39      25.1               20              207750000.0   \n",
      "419  ...         37      25.1               29               95100000.0   \n",
      "420  ...         34      25.4               18               93400000.0   \n",
      "421  ...         34      25.4               18               93400000.0   \n",
      "422  ...         33      24.5               22              446150000.0   \n",
      "423  ...         39      23.7               20              137330000.0   \n",
      "424  ...         38      24.7               21              296000000.0   \n",
      "425  ...         35      24.0               24               72100000.0   \n",
      "426  ...         42      23.7               23               76800000.0   \n",
      "427  ...         42      23.5               25              365500000.0   \n",
      "\n",
      "     Average Market Value_Home  Squad_Away  Age_Away  Foreigners_Away  \\\n",
      "418                  5330000.0          39      25.1               23   \n",
      "419                  2570000.0          32      23.9               21   \n",
      "420                  2750000.0          34      27.5               27   \n",
      "421                  2750000.0          34      27.5               27   \n",
      "422                 13520000.0          37      24.3               24   \n",
      "423                  3520000.0          34      25.8               18   \n",
      "424                  7790000.0          45      23.4               27   \n",
      "425                  2060000.0          45      24.3               23   \n",
      "426                  1830000.0          33      27.0               20   \n",
      "427                  8700000.0          34      23.4               27   \n",
      "\n",
      "     Total Market Value_Away  Average Market Value_Away  \n",
      "418              158950000.0                  4080000.0  \n",
      "419              178530000.0                  5580000.0  \n",
      "420              111950000.0                  3290000.0  \n",
      "421              111950000.0                  3290000.0  \n",
      "422               85030000.0                  2300000.0  \n",
      "423              102900000.0                  3030000.0  \n",
      "424              382530000.0                  8500000.0  \n",
      "425               38100000.0                   886000.0  \n",
      "426               96400000.0                  2920000.0  \n",
      "427              304380000.0                  8950000.0  \n",
      "\n",
      "[10 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "##########################################################\n",
    "# Construct main dataframe - Marcel\n",
    "##########################################################\n",
    "\n",
    "main_files = glob.glob('../data/raw/E0_*.csv')\n",
    "\n",
    "dataframes = []\n",
    "start_year = 2010\n",
    "for i, file in enumerate(main_files):\n",
    "    df = pd.read_csv(file, sep=',', index_col=None, header=0, error_bad_lines=False, parse_dates=[1], dayfirst=True)\n",
    "    year = file.split(\".csv\")[0].split(\"E0_\")[-1]\n",
    "    #df['Season'] = np.zeros((df['Div'].values.shape[0])) + int(year)\n",
    "    df['Season'] = start_year + i\n",
    "    dataframes.append(df)\n",
    "\n",
    "main_df = pd.concat(dataframes, sort=False)\n",
    "cols_to_drop = [c for c in list(main_df.columns[26:]) if c != 'Season']\n",
    "print(cols_to_drop)\n",
    "main_df = main_df.drop(columns=cols_to_drop).dropna()\n",
    "##########################################################\n",
    "# Ali's Datasets Merge\n",
    "##########################################################\n",
    "\n",
    "ali_files = glob.glob('../data/ali_raw/201*.csv')\n",
    "\n",
    "ali_frames = []\n",
    "\n",
    "for i, file in enumerate(ali_files):\n",
    "    data = pd.read_csv(file, sep = ',')\n",
    "    year = file.split(\".csv\")[0].split(\"/\")[-1]\n",
    "    #data['Season'] = np.zeros((data['Div'].values.shape[0])) + int(year)\n",
    "    data['Season'] = start_year + i\n",
    "    # Drop the last row\n",
    "    data.drop(data.tail(1).index,inplace=True)\n",
    "    ali_frames.append(data)\n",
    "\n",
    "ali_df = pd.concat(ali_frames, sort = False)\n",
    "\n",
    "# Modify Foreigners to integer\n",
    "ali_df['Foreigners'] = ali_df['Foreigners'].astype(int)\n",
    "\n",
    "# Modify Age to Float\n",
    "ali_df['Age'] = ali_df['Age'].apply(lambda x: x.replace(\",\",\".\")).astype(float)\n",
    "\n",
    "# Modify Total Market value\n",
    "ali_df['Total Market Value'] = ali_df['Total Market Value'].apply(lambda x: x.replace(\",\",\"\"))\n",
    "ali_df['Total Market Value'] = ali_df['Total Market Value'].apply(lambda x: x.replace(\" Bill. €\",\"0000000\"))\n",
    "ali_df['Total Market Value'] = ali_df['Total Market Value'].apply(lambda x: x.replace(\" Mill. €\",\"0000\"))\n",
    "ali_df['Total Market Value'] = ali_df['Total Market Value'].apply(lambda x: x.replace(\" Th. €\",\"000\")).astype(float)\n",
    "\n",
    "# Modify Average Market value\n",
    "ali_df['Average Market Value'] = ali_df['Average Market Value'].apply(lambda x: x.replace(\",\",\"\"))\n",
    "ali_df['Average Market Value'] = ali_df['Average Market Value'].apply(lambda x: x.replace(\" Mill. €\",\"0000\"))\n",
    "ali_df['Average Market Value'] = ali_df['Average Market Value'].apply(lambda x: x.replace(\" Th. €\",\"000\")).astype(float)\n",
    "\n",
    "\n",
    "#Load Name & Club Key\n",
    "name_df = pd.read_csv('../data/ali_raw/club_home_names.csv', sep = \",\")\n",
    "name_df = name_df[['Club_Name','Home_Name']]\n",
    "ali_df = ali_df.merge(name_df, how = \"left\", left_on = ['Club'], right_on = ['Club_Name'])\n",
    "ali_df = ali_df.drop(columns = [\"Club\", \"Club_Name\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(ali_df.head(10))\n",
    "\n",
    "main_df = main_df.merge(ali_df, how = 'left', left_on = ['Season', 'HomeTeam'], right_on = ['Season', 'Home_Name'])\n",
    "main_df = main_df.merge(ali_df, how = 'left', left_on = ['Season', 'AwayTeam'], right_on = ['Season', 'Home_Name'], suffixes = (\"_Home\", \"_Away\"))\n",
    "\n",
    "main_df = main_df.drop(columns = [\"Home_Name_Home\", \"Home_Name_Away\"])\n",
    "\n",
    "##########################################################\n",
    "# Anu's Datasets Merge\n",
    "##########################################################\n",
    "'''\n",
    "def convert_name(name):\n",
    "    d = {'Chelsea': 'Chelsea', 'Bolton Wanderers': 'Bolton', 'Portsmouth': 'Portsmouth', 'Blackburn Rovers': 'Blackburn',\n",
    "     'Stoke City': 'Stoke', 'Aston Villa': 'Aston Villa', 'Wolverhampton Wanderers': 'Wolves', 'Everton': 'Everton',\n",
    "     'Manchester United': 'Man United', 'Tottenham Hotspur': 'Tottenham', 'Sunderland': 'Sunderland', 'Wigan Athletic': 'Wigan',\n",
    "     'Hull City': 'Hull', 'Burnley': 'Burnley', 'Birmingham City': 'Birmingham', 'Liverpool': 'Liverpool', 'Manchester City': 'Man City',\n",
    "     'Arsenal': 'Arsenal', 'West Ham United': 'West Ham', 'Fulham': 'Fulham', 'West Bromwich Albion': 'West Brom', 'Newcastle United': 'Newcastle',\n",
    "     'Blackpool': 'Blackpool', 'Queens Park Rangers': 'QPR', 'Swansea City': 'Swansea', 'Norwich City': 'Norwich', 'Reading': 'Reading',\n",
    "     'Southampton': 'Southampton', 'Crystal Palace': 'Crystal Palace', 'Cardiff City': 'Cardiff', 'Leicester City': 'Leicester', 'Bournemouth': 'Bournemouth',\n",
    "     'Watford': 'Watford', 'Middlesbrough': 'Middlesbrough', 'Brighton & Hove Albion': 'Brighton', 'Huddersfield Town': 'Huddersfield'}\n",
    "\n",
    "    return d[name]\n",
    "\n",
    "rosters_df = pd.read_csv(\"../data/anu/processed_rosters_full.csv\")\n",
    "\n",
    "rosters_df['HomeTeam'] = rosters_df['HomeTeam'].apply(lambda x: convert_name(x))\n",
    "rosters_df['AwayTeam'] = rosters_df['AwayTeam'].apply(lambda x: convert_name(x))\n",
    "\n",
    "main_df = main_df.merge(rosters_df, how='left', on=['Season', 'HomeTeam', 'AwayTeam'])\n",
    "'''\n",
    "##########################################################\n",
    "# Ravi's Datasets Merge\n",
    "##########################################################\n",
    "'''\n",
    "google_trends_df = pd.read_csv(\"../data/ravi/google_trends.csv\")\n",
    "main_df = main_df.merge(google_trends_df, how='left', on=['Season', 'HomeTeam', 'AwayTeam'])\n",
    "\n",
    "'''\n",
    "##########################################################\n",
    "# Merge Additional Dataset Weather - Orestis\n",
    "#########################################################\n",
    "\n",
    "def convert_name_weather(name):\n",
    "    # Convert names for the weather data\n",
    "\n",
    "    d = {'Chelsea': 'Chelsea', 'Bolton': 'Bolton', 'Portsmouth': 'Portsmouth', 'Blackburn': 'Blackburn',\n",
    "     'Stoke City': 'Stoke','Stoke':\"Stoke\", 'Aston Villa': 'Aston Villa', 'Wolves': 'Wolves', 'Everton': 'Everton',\n",
    "     'Manchester United': 'Man United', 'Tottenham Hotspur': 'Tottenham', 'Sunderland': 'Sunderland', 'Wigan': 'Wigan',\n",
    "     'Hull': 'Hull', 'Burnley': 'Burnley', 'Birmingham': 'Birmingham', 'Liverpool': 'Liverpool', 'Manchester City': 'Man City',\n",
    "     'Arsenal': 'Arsenal', 'West Ham United': 'West Ham', 'Fulham': 'Fulham', 'West Bromwich Albion': 'West Brom', 'Newcastle United': 'Newcastle',\n",
    "     'Blackpool': 'Blackpool', 'QPR': 'QPR', 'Swansea City': 'Swansea', 'Norwich': 'Norwich', 'Reading': 'Reading',\n",
    "     'Southampton': 'Southampton', 'Crystal Palace': 'Crystal Palace', 'Cardiff': 'Cardiff', 'Leicester City': 'Leicester', 'Bournemouth': 'Bournemouth',\n",
    "     'Watford': 'Watford', 'Middlesbrough': 'Middlesbrough', 'Brighton': 'Brighton', 'Huddersfield Town': 'Huddersfield'}\n",
    "\n",
    "    return d[name]\n",
    "\n",
    "all_files_weather = glob.glob('../data/weather/preprocessed/*.csv')\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files_weather:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "weather_frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "weather_frame['HomeTeam'] = weather_frame['HomeTeam'].apply(lambda x: convert_name_weather(x))\n",
    "weather_frame['datetime_est'] = pd.to_datetime(weather_frame['datetime_est'])\n",
    "weather_frame['datetime_est'] = weather_frame['datetime_est'].dt.normalize()\n",
    "\n",
    "for colum in ['temp','wx_phrase','heat_index','pressure','vis']:\n",
    "    weather_frame[colum].fillna(method='ffill',inplace=True)\n",
    "    weather_frame[colum].fillna(method='bfill',inplace=True)\n",
    "\n",
    "#weather_frame[['temp','wx_phrase','heat_index','pressure','vis']].fillna(method='ffill',inplace=True)\n",
    "#weather_frame[['temp','wx_phrase','heat_index','pressure','vis']].fillna(method='bfill',inplace=True)\n",
    "weather_frame.drop_duplicates(subset= 'datetime_est',keep='first',inplace=True)\n",
    "#weather_frame.fillna(method='bfill')\n",
    "\n",
    "\n",
    "#main_df = main_df.merge(weather_frame, how = 'left', left_on = ['Date', 'HomeTeam'], right_on = ['datetime_est', 'HomeTeam'])\n",
    "\n",
    "##########################################################\n",
    "# Rachel's Dataset Merge\n",
    "#########################################################\n",
    "'''\n",
    "wage_bill_df = pd.read_csv(\"../data/rachel_raw/Master.csv\")\n",
    "main_df = main_df.merge(wage_bill_df, how='left', on=['Season', 'HomeTeam', 'AwayTeam'])\n",
    "'''\n",
    "##########################################################\n",
    "# Sponsorship Data - Laura\n",
    "#########################################################\n",
    "'''\n",
    "#Getting and melting raw csv file\n",
    "sponsorship_data_df = pd.read_csv(\"../data/sponsorship_raw/SponsorshipData.csv\")\n",
    "sponsorship_data_df = pd.melt(sponsorship_data_df, id_vars=[\"Team\"], var_name=\"Season\", value_name=\"SponsorshipAmount\")\n",
    "\n",
    "#Converting season to integer for merging purposes\n",
    "sponsorship_data_df['Season'] = sponsorship_data_df['Season'].astype(int)\n",
    "\n",
    "#Merge sponsorhip with Home Team\n",
    "main_df = main_df.merge(sponsorship_data_df, how='left', left_on=['Season', 'HomeTeam'], right_on = ['Season', 'Team'])\n",
    "main_df = main_df.rename(columns={'SponsorshipAmount': 'SponsorshipAmount_HomeTeam'})\n",
    "main_df = main_df.drop(['Team'], axis=1)\n",
    "\n",
    "#Merge sponsorship with Away Team\n",
    "main_df = main_df.merge(sponsorship_data_df, how='left', left_on=['Season', 'AwayTeam'], right_on = ['Season', 'Team'])\n",
    "main_df = main_df.rename(columns={'SponsorshipAmount': 'SponsorshipAmount_AwayTeam'})\n",
    "main_df = main_df.drop(['Team'], axis=1)\n",
    "'''\n",
    "##########################################################\n",
    "# Merge Trade Data - Mihir\n",
    "#########################################################\n",
    "'''\n",
    "\n",
    "trade_df = pd.read_csv(\"../data/MihirT_TradeData.csv\")\n",
    "\n",
    "#Converting season to integer for merging purposes\n",
    "trade_df['Season'] = trade_df['Season'].astype(int)\n",
    "\n",
    "#Merge trade data with Home Team\n",
    "main_df = main_df.merge(trade_df, how='left', left_on=['Season', 'HomeTeam'], right_on = ['Season', 'Team'])\n",
    "main_df = main_df.rename(columns={'NumIn': 'Home_NumIn', 'NumOut': 'Home_NumOut', 'DepAge': 'Home_DepAge', 'ArrAge': 'Home_ArrAge', 'MarketDep': 'Home_MarketDep', 'MarketArr': 'Home_MarketArr', 'Income': 'Home_Income', 'Expenditures': 'Home_Expenditures'})\n",
    "main_df = main_df.drop(['Team'], axis=1)\n",
    "\n",
    "#Merge trade data with Away Team\n",
    "main_df = main_df.merge(trade_df, how='left', left_on=['Season', 'AwayTeam'], right_on = ['Season', 'Team'])\n",
    "main_df = main_df.rename(columns={'NumIn': 'Away_NumIn', 'NumOut': 'Away_NumOut', 'DepAge': 'Away_DepAge', 'ArrAge': 'Away_ArrAge', 'MarketDep': 'Away_MarketDep', 'MarketArr': 'Away_MarketArr', 'Income': 'Away_Income', 'Expenditures': 'Away_Expenditures'})\n",
    "main_df = main_df.drop(['Team'], axis=1)\n",
    "'''\n",
    "# Remove the 2010 season since we don't have complete data\n",
    "\n",
    "main_df = main_df[main_df['Season'] != 2010]\n",
    "\n",
    "print(main_df.head(10))\n",
    "\n",
    "#main_df.to_csv('../data/preprocessed/football.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather_frame[weather_frame['datetime_est']>'2010' & weather_frame['HomeTeam']=='Arsenal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mostly Cloudy', 'Mostly Cloudy / Windy', 'Fair', 'Cloudy',\n",
       "       'Partly Cloudy', 'Cloudy / Windy', 'Partly Cloudy / Windy',\n",
       "       'Fair / Windy', 'Fog', 'Mist', 'Shallow Fog', 'Haze', 'Light Rain',\n",
       "       'Patches of Fog', 'T-Storm', 'Light Rain Shower', 'Rain',\n",
       "       'Light Drizzle', 'Rain Shower', 'Rain / Windy',\n",
       "       'Light Rain / Windy', 'Rain and Snow', 'Light Snow',\n",
       "       'Showers in the Vicinity', 'Light Drizzle / Windy', 'Heavy Rain',\n",
       "       'Partial Fog', 'Wintry Mix', 'Light Snow / Windy'], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_frame['wx_phrase'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
